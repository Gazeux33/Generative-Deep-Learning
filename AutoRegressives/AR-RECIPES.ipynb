{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:12.281232Z",
     "start_time": "2024-03-14T13:03:12.270345Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"../data/Epicurious-Recipes/full_format_recipes.json\",\"r\") as json_data:\n",
    "    data = json.load(json_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:12.640436Z",
     "start_time": "2024-03-14T13:03:12.283185Z"
    }
   },
   "id": "6dfd468a338ec7a4",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data = [\n",
    "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
    "    for x in data\n",
    "    if \"title\" in x\n",
    "    and x[\"title\"] is not None\n",
    "    and \"directions\" in x\n",
    "    and x[\"directions\"] is not None\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:12.661756Z",
     "start_time": "2024-03-14T13:03:12.641845Z"
    }
   },
   "id": "1545ee1f4d748b39",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Recipe for Lentil, Apple, and Turkey Wrap  | 1. Place the stock, lentils, celery, carrot, thyme, and salt in a medium saucepan and bring to a boil. Reduce heat to low and simmer until the lentils are tender, about 30 minutes, depending on the lentils. (If they begin to dry out, add water as needed.) Remove and discard the thyme. Drain and transfer the mixture to a bowl; let cool. 2. Fold in the tomato, apple, lemon juice, and olive oil. Season with the pepper. 3. To assemble a wrap, place 1 lavash sheet on a clean work surface. Spread some of the lentil mixture on the end nearest you, leaving a 1-inch border. Top with several slices of turkey, then some of the lettuce. Roll up the lavash, slice crosswise, and serve. If using tortillas, spread the lentils in the center, top with the turkey and lettuce, and fold up the bottom, left side, and right side before rolling away from you.'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:12.666436Z",
     "start_time": "2024-03-14T13:03:12.663850Z"
    }
   },
   "id": "386a1f030a259c47",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import layers\n",
    "import string\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:12.689686Z",
     "start_time": "2024-03-14T13:03:12.667085Z"
    }
   },
   "id": "d3964fa993299bc0",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pad the punctuation, to treat them as separate 'words'\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:13.575614Z",
     "start_time": "2024-03-14T13:03:12.690170Z"
    }
   },
   "id": "b0c435b9cf601ddc",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_ds = Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:13.762269Z",
     "start_time": "2024-03-14T13:03:13.576496Z"
    }
   },
   "id": "db2f9bff724b8a7b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=10000,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=200+1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:13.778711Z",
     "start_time": "2024-03-14T13:03:13.762816Z"
    }
   },
   "id": "85a31fc772f146fc",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:14.378335Z",
     "start_time": "2024-03-14T13:03:13.779270Z"
    }
   },
   "id": "5c3b95502cea44ce",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1 [UNK]\n",
      "2 .\n",
      "3 ,\n",
      "4 and\n",
      "5 to\n",
      "6 in\n",
      "7 the\n",
      "8 with\n",
      "9 a\n"
     ]
    }
   ],
   "source": [
    "best_vocab = vocab[:10]\n",
    "for i,word in enumerate(best_vocab):\n",
    "    print(i,word)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:06:55.637027Z",
     "start_time": "2024-03-14T13:06:55.630751Z"
    }
   },
   "id": "8610d8a21a159585",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  26   16 2783   13 2783    6  265  252   54   27   17   37    6   78\n",
      "   30   56   20   29   13   75   17    2   18  115   22  130   10  861\n",
      "    4  473    5   91    3   19   32   12    2   18  249    4 1413  345\n",
      "    2   69   10  288    5   36   23   32   52    3   19   36   12    2\n",
      "   18  182    8  104   22   84    5   69    2   88  213    8   24    4\n",
      "   33    2   18  213    5   56  475  265   31    2  153   17    5  134\n",
      "    3   49    3    4   70   10  213   38  183  102    3   19  334   12\n",
      "    2   87  308  445  384    3   40  213    5  219    4  940    8  167\n",
      "    5  186  152    2  116  531    3   15  410  639    3    4  247  175\n",
      "   25   54    6   56    2  547   17    5   75    4   69   10   54   38\n",
      "  288    4  426    3   19  118   12    2   63    5  132    8   24    4\n",
      "   33    2   64   11  213  982   28   66   14   32  280    2  107   54\n",
      "   20    4  276  213    3   88    8   45   11  142  639    3    4   68\n",
      "    8  152  589  195    2    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "example = text_data[3]\n",
    "encoded_example = vectorize_layer(example)\n",
    "print(encoded_example.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:03:14.405150Z",
     "start_time": "2024-03-14T13:03:14.380048Z"
    }
   },
   "id": "afbf0a24adf1c9ef",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_inputs(text):\n",
    "    text = tf.expand_dims(text,-1)\n",
    "    tokenized_sentence = vectorize_layer(text)\n",
    "    x = tokenized_sentence[:,:-1]\n",
    "    y = tokenized_sentence[:,1:]\n",
    "    return x,y\n",
    "train_ds = text_ds.map(prepare_inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:06:18.176585Z",
     "start_time": "2024-03-15T09:06:18.019210Z"
    }
   },
   "id": "6ee6902e734a4d2a",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
