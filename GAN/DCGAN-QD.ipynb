{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.351871Z",
     "start_time": "2024-03-13T17:02:59.334821Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils.ImageGenerator import ImageGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.358010Z",
     "start_time": "2024-03-13T17:02:59.355427Z"
    }
   },
   "id": "ed79311963187f5a",
   "execution_count": 270
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and Process the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c580962ae5d57ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = np.load(\"../data/full_numpy_bitmap_dragon.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.429470Z",
     "start_time": "2024-03-13T17:02:59.360543Z"
    }
   },
   "id": "4d4eae0d8cb569f7",
   "execution_count": 271
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = data.reshape((-1,28,28,1))\n",
    "data = data.astype(\"float32\")/255\n",
    "data = data[:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.654489Z",
     "start_time": "2024-03-13T17:02:59.433140Z"
    }
   },
   "id": "22c327946871190e",
   "execution_count": 272
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(124362, 28, 28, 1)"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.666126Z",
     "start_time": "2024-03-13T17:02:59.655445Z"
    }
   },
   "id": "a2b31f98dd735aa",
   "execution_count": 273
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(data.min())\n",
    "print(data.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.693073Z",
     "start_time": "2024-03-13T17:02:59.668320Z"
    }
   },
   "id": "f1da0f22aa0649e2",
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x176495a50>"
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[np.random.choice(len(data))],cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.847288Z",
     "start_time": "2024-03-13T17:02:59.694269Z"
    }
   },
   "id": "4ebfe575f329af4e",
   "execution_count": 275
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Z_DIM = 128\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.0001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.851372Z",
     "start_time": "2024-03-13T17:02:59.848958Z"
    }
   },
   "id": "76a8c2e364cb6a84",
   "execution_count": 276
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,models,losses,optimizers,metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:02:59.855208Z",
     "start_time": "2024-03-13T17:02:59.852701Z"
    }
   },
   "id": "7908620e5440a6a4",
   "execution_count": 277
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discriminator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e81e32bd525e90b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 14, 14, 64)        1088      \n",
      "                                                                 \n",
      " leaky_re_lu_39 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 7, 7, 128)         131200    \n",
      "                                                                 \n",
      " leaky_re_lu_40 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 4, 4, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_41 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 396609 (1.51 MB)\n",
      "Trainable params: 396609 (1.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs  = layers.Input(shape=(28, 28, 1))\n",
    "x       = layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\")(inputs)\n",
    "x       = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x       = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x       = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x       = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x       = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x       = layers.Flatten()(x)\n",
    "x       = layers.Dropout(0.2)(x)\n",
    "z       = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "discriminator = models.Model(inputs, z, name=\"discriminator\")\n",
    "discriminator.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:00.062138Z",
     "start_time": "2024-03-13T17:02:59.856670Z"
    }
   },
   "id": "7c66bd2c8059dc8",
   "execution_count": 278
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90fd930bd6b19666"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3136)              404544    \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " up_sampling2d_26 (UpSampli  (None, 14, 14, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " up_sampling2d_27 (UpSampli  (None, 28, 28, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 28, 28, 1)         6401      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 779969 (2.98 MB)\n",
      "Trainable params: 779969 (2.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs  = layers.Input(shape=(Z_DIM,))\n",
    "x       = layers.Dense(7 * 7 * 64)(inputs)\n",
    "x       = layers.Reshape((7, 7, 64))(x)\n",
    "x       = layers.UpSampling2D()(x)\n",
    "x       = layers.Conv2D(128,  kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "x       = layers.UpSampling2D()(x)\n",
    "x       = layers.Conv2D(256,  kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "outputs = layers.Conv2D(1,    kernel_size=5, strides=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "generator = models.Model(inputs, outputs, name=\"generator\")\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:00.132850Z",
     "start_time": "2024-03-13T17:03:00.063523Z"
    }
   },
   "id": "798fa04d1b502cf7",
   "execution_count": 279
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DCGAN Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24168f87cfd2b7e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DCGAN(models.Model):\n",
    "    def __init__(self,my_discriminator,my_generator,z_dim=Z_DIM):\n",
    "        super(DCGAN,self).__init__()\n",
    "        \n",
    "        self.discriminator = my_discriminator\n",
    "        self.generator = my_generator\n",
    "        self.z_dim = z_dim\n",
    "        self.discriminator_opt = None\n",
    "        self.generator_opt = None\n",
    "        self.loss_fn = None\n",
    "        self.g_loss = None\n",
    "        self.d_loss = None\n",
    "        \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # This method should handle both real and generated images\n",
    "        return self.generator(inputs)\n",
    "    \n",
    "    def compile(self,d_opt,g_opt,loss_fn):\n",
    "        super(DCGAN,self).compile()\n",
    "        self.discriminator_opt = d_opt\n",
    "        self.generator_opt = g_opt\n",
    "        self.loss_fn = loss_fn\n",
    "        self.discriminator.compile(optimizer=self.discriminator_opt,loss=self.loss_fn)\n",
    "        self.generator.compile(optimizer=self.generator_opt,loss=self.loss_fn)\n",
    "        self.d_loss = metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss = metrics.Mean(name=\"g_loss\")\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss,self.g_loss]\n",
    "    \n",
    "    def train_step(self, real_imgs):\n",
    "        batch_size = tf.shape(real_imgs)[0]\n",
    "        sample_vector = tf.random.normal(shape=(batch_size, self.z_dim))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(sample_vector)\n",
    "            concat_imgs = tf.concat([real_imgs, generated_images], axis=0)\n",
    "            labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "            predictions = self.discriminator(concat_imgs)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "            \n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.discriminator_opt.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "        \n",
    "        sample_vector = tf.random.normal(shape=(batch_size, self.z_dim))\n",
    "        false_labels = tf.ones((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_imgs = self.generator(sample_vector)\n",
    "            d_predictions = self.discriminator(fake_imgs)\n",
    "            g_loss = self.loss_fn(false_labels, d_predictions)\n",
    "            \n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.generator_opt.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        \n",
    "        self.g_loss.update_state(g_loss)\n",
    "        self.d_loss.update_state(d_loss)\n",
    "        \n",
    "        return {\n",
    "            \"d_loss\": self.d_loss.result(),\n",
    "            \"g_loss\": self.g_loss.result()\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:00.159907Z",
     "start_time": "2024-03-13T17:03:00.141905Z"
    }
   },
   "id": "57c998a349ccb325",
   "execution_count": 280
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dcgan = DCGAN(discriminator,generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:00.167527Z",
     "start_time": "2024-03-13T17:03:00.161691Z"
    }
   },
   "id": "e7fbdd042b7ea591",
   "execution_count": 281
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "d_opt = optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "g_opt = optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fn = losses.BinaryCrossentropy()\n",
    "\n",
    "dcgan.compile(d_opt,g_opt,loss_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:00.189519Z",
     "start_time": "2024-03-13T17:03:00.169284Z"
    }
   },
   "id": "caf3ec16ce9cff30",
   "execution_count": 282
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  2/972 [..............................] - ETA: 20:25 - d_loss: 0.6862 - g_loss: 0.7532"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[283], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dcgan\u001B[38;5;241m.\u001B[39mfit(data,batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,callbacks\u001B[38;5;241m=\u001B[39mImageGenerator(\u001B[38;5;241m10\u001B[39m,Z_DIM,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),epochs\u001B[38;5;241m=\u001B[39mEPOCHS)\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    869\u001B[0m       args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_config\n\u001B[1;32m    870\u001B[0m   )\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[1;32m    141\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mcall_preflattened(args)\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall_flat(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[1;32m   1487\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1488\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   1489\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[1;32m   1490\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[1;32m   1491\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1492\u001B[0m   )\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/anaconda3/envs/DeepLearning/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dcgan.fit(data,batch_size=128,callbacks=ImageGenerator(10,Z_DIM,\"callbacks\"),epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:05.042145Z",
     "start_time": "2024-03-13T17:03:00.193419Z"
    }
   },
   "id": "54c2e06f9460b79e",
   "execution_count": 283
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate new Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a67476ed1009037"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nb_img = 10\n",
    "\n",
    "z = np.random.normal(size=(nb_img,Z_DIM,1))\n",
    "print(z.shape)\n",
    "\n",
    "predictions = dcgan.predict(z)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T17:03:05.043078Z",
     "start_time": "2024-03-13T17:03:05.043023Z"
    }
   },
   "id": "814b618e9c967fbd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predictions.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcbace8a48e7aa5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(predictions[6],cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6eda2a8a282fec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dcgan.save(\"dcgan-qd-dragon.keras\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f039404d297aec4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
