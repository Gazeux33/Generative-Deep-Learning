{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33fb5df76d497fd7"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.034870Z",
     "start_time": "2024-03-15T09:07:06.029429Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Consts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe231739028da2d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Z_DIM = 128 # latent dim used\n",
    "EPOCHS = 3 # number of epochs\n",
    "LEARNING_RATE = 0.0001 # learning rate\n",
    "BATCH_SIZE = 64 # size of batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.057742Z",
     "start_time": "2024-03-15T09:07:06.054937Z"
    }
   },
   "id": "c0a7290720344e5e",
   "execution_count": 144
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and Process the Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "327a077c42a91e85"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = np.load(\"../data/full_numpy_bitmap_flower.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.129852Z",
     "start_time": "2024-03-15T09:07:06.058592Z"
    }
   },
   "id": "6b5bf813a7190350",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(144818, 28, 28, 1)"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape and normalize images\n",
    "data = data.reshape((-1, 28, 28, 1))\n",
    "data = data.astype(\"float32\") / 255\n",
    "data = data[:]\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.433386Z",
     "start_time": "2024-03-15T09:07:06.132456Z"
    }
   },
   "id": "7c4d50d4cd07e17a",
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x164508050>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing an image\n",
    "plt.imshow(data[np.random.choice(len(data))],cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.562247Z",
     "start_time": "2024-03-15T09:07:06.434066Z"
    }
   },
   "id": "a40bb26d10004dbc",
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.568344Z",
     "start_time": "2024-03-15T09:07:06.564448Z"
    }
   },
   "id": "f60af0ab6804644",
   "execution_count": 148
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the Critic \n",
    "the discriminator has become a critic.The difference between these two things is that the drisciminator \n",
    "performs a classification while the critic just gives a score on ]−∞;+∞[ (no sigmoid)\n",
    "+∞ = real\n",
    "−∞ = fake\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3666cf5f3409f497"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"critic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 14, 14, 64)        1088      \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 7, 7, 128)         131200    \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 4, 4, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 396609 (1.51 MB)\n",
      "Trainable params: 396609 (1.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic_input  = layers.Input(shape=(28, 28, 1))\n",
    "x                   = layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\")(critic_input)\n",
    "x                   = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x                   = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x                   = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x                   = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x                   = layers.LeakyReLU(alpha=0.2)(x)\n",
    "x                   = layers.Flatten()(x)\n",
    "x                   = layers.Dropout(0.2)(x)\n",
    "critic_output       = layers.Dense(1)(x)\n",
    "\n",
    "critic = models.Model(critic_input, critic_output, name=\"critic\")\n",
    "critic.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.723765Z",
     "start_time": "2024-03-15T09:07:06.569360Z"
    }
   },
   "id": "139d38d630cc7ba3",
   "execution_count": 149
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the Generator "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50afc013d807fcab"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3136)              404544    \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSampli  (None, 14, 14, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSampli  (None, 28, 28, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 28, 28, 1)         6401      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 779969 (2.98 MB)\n",
      "Trainable params: 779969 (2.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input  = layers.Input(shape=(Z_DIM,))\n",
    "x       = layers.Dense(7 * 7 * 64)(generator_input)\n",
    "x       = layers.Reshape((7, 7, 64))(x)\n",
    "x       = layers.UpSampling2D()(x)\n",
    "x       = layers.Conv2D(128,  kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "x       = layers.UpSampling2D()(x)\n",
    "x       = layers.Conv2D(256,  kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "generator_output = layers.Conv2D(1,    kernel_size=5, strides=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "generator = models.Model(generator_input, generator_output, name=\"generator\")\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.797134Z",
     "start_time": "2024-03-15T09:07:06.725103Z"
    }
   },
   "id": "83e1e20290daac40",
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e83d84f80ecf4f",
   "execution_count": 151
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the WDCGAN-GP Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52a2be63a364686"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DCGAN(models.Model):\n",
    "    def __init__(self,my_critic,my_generator,z_dim=128,n_critic=3,lambda_gp=10,**kwargs):\n",
    "        super(DCGAN,self).__init__(**kwargs)\n",
    "\n",
    "        self.critic = my_critic\n",
    "        self.generator = my_generator\n",
    "        self.z_dim = z_dim\n",
    "        self.latent_dim = z_dim\n",
    "        self.n_critic = n_critic\n",
    "        self.lambda_gp = lambda_gp\n",
    "        \n",
    "        self.critic_opt = None\n",
    "        self.generator_opt = None\n",
    "        self.loss_fn = None\n",
    "        self.g_loss = None\n",
    "        self.c_loss = None\n",
    "        self.gp = None\n",
    "        \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        return self.generator(inputs)\n",
    "    \n",
    "    def compile(self,d_opt,g_opt):\n",
    "        super(DCGAN,self).compile()\n",
    "        self.critic_opt = d_opt\n",
    "        self.generator_opt = g_opt\n",
    "        self.critic.compile(optimizer=self.critic_opt)\n",
    "        self.generator.compile(optimizer=self.generator_opt)\n",
    "        self.c_loss = metrics.Mean(name=\"c_loss\")\n",
    "        self.g_loss = metrics.Mean(name=\"g_loss\")\n",
    "        self.gp = metrics.Mean(name=\"gp\")\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.c_loss,self.g_loss,self.gp]\n",
    "    \n",
    "    def gradient_penalty(self,batch_size,real_images,fake_images):\n",
    "        epsilon = tf.random.normal([batch_size,1,1,1],0.0,1.0)\n",
    "        interpolated = fake_images+epsilon*(real_images-fake_images)\n",
    "        \n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            interpolated_critics = self.critic(interpolated,training=True)\n",
    "        gradients = gp_tape.gradient(interpolated_critics,[interpolated])[0]\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(gradients),axis=[1,2,3]))\n",
    "        gp = self.lambda_gp * tf.reduce_mean((norm-1.0)**2)\n",
    "        return gp\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        #*****TRAIN THE CRITIC*****\n",
    "        for i in range(self.n_critic):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
    "            fake_images = self.generator(random_latent_vectors,training=True)\n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "                # get critics for the fake images : D(G(z))\n",
    "                fake_critics = self.critic(fake_images,training=True)\n",
    "                \n",
    "                # get  critics for the real images : D(x)\n",
    "                real_critics = self.critic(real_images,training=True)\n",
    "                \n",
    "                # Calculate the wasserstein discriminator loss: L = D(fake)-D(real)\n",
    "                w_loss = tf.reduce_mean(fake_critics) - tf.reduce_mean(real_critics)\n",
    "                \n",
    "                # Caluculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size,real_images,fake_images)\n",
    "                \n",
    "                d_loss = w_loss + gp\n",
    "                \n",
    "            gradients = tape.gradient(d_loss,self.critic.trainable_weights)\n",
    "            self.critic_opt.apply_gradients(zip(gradients,self.critic.trainable_weights))\n",
    "            self.c_loss.update_state(d_loss)\n",
    "            self.gp.update_state(gp)\n",
    "          \n",
    "        #*****TRAIN THE GENERATOR*****\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_latent_vectors,training=True)\n",
    "            fake_critics = self.critic(fake_images)\n",
    "            g_loss = -tf.reduce_mean(fake_critics)\n",
    "        gradients = tape.gradient(g_loss,self.generator.trainable_variables)\n",
    "        self.generator_opt.apply_gradients(zip(gradients,self.generator.trainable_variables))\n",
    "        self.g_loss.update_state(g_loss)\n",
    "        \n",
    "       \n",
    "        \n",
    "        return {\n",
    "            \"c_loss\": self.c_loss.result(),\n",
    "            \"g_loss\": self.g_loss.result(),\n",
    "            \"gp\":self.gp.result()\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.813360Z",
     "start_time": "2024-03-15T09:07:06.801757Z"
    }
   },
   "id": "3c37d6cce3aee60",
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from utils.ImageGenerator import ImageGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.817600Z",
     "start_time": "2024-03-15T09:07:06.814383Z"
    }
   },
   "id": "d4a43d1d398e0d1",
   "execution_count": 153
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37379c3f53bd2efb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dcgan = DCGAN(critic,generator,z_dim=Z_DIM)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.824372Z",
     "start_time": "2024-03-15T09:07:06.820263Z"
    }
   },
   "id": "c305ab4871d2cfbd",
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "c_opt = optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "g_opt = optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "dcgan.compile(c_opt,g_opt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:06.850174Z",
     "start_time": "2024-03-15T09:07:06.826336Z"
    }
   },
   "id": "20a23e76f15cc039",
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = dcgan.fit(data,batch_size=BATCH_SIZE,callbacks=ImageGenerator(10,Z_DIM,\"callbacks\"),epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:07:08.980237Z",
     "start_time": "2024-03-15T09:07:06.851901Z"
    }
   },
   "id": "688d73b7191d8ba7",
   "execution_count": 156
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad8621a074e150cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dcgan.save(\"wdcgan-gp-qd-flower.keras\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb5328fa01a77740",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97a7f0b67b97bd3c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nb_img = 5\n",
    "z = np.random.normal(size=(nb_img, Z_DIM, 1))\n",
    "predictions = dcgan.predict(z,verbose=False)\n",
    "\n",
    "fig,axs = plt.subplots(1,nb_img)\n",
    "for i in range(nb_img):\n",
    "    axs[i].imshow(predictions[i],cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf78f7c8d252350f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
